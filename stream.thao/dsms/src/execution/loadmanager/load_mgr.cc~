/*
 * @file       load_mgr.cc
 * @date       Mar 24, 2009
 * @brief      Implementation of the load manager
 * @author     Thao N Pham
 */
 #include <iostream>
 #include <math.h>
 #include <stdlib.h>
 
using namespace std;

#ifndef _DEBUG_
#include "common/debug.h"
#endif

#ifndef _LOAD_MGR_
#include "execution/loadmanager/load_mgr.h"
#endif

using namespace Physical;
using namespace Execution;
LoadManager::LoadManager()
{
	this -> numDrops = 0;	
	//this -> usedOps = 0;
	this->numInputs = 0;
	this->numOutputs = 0;
	this->numOps = 0;
	this->abnormal_cost = 0;
	this->numOfStableSheddingCycles = 0;
	this->overloadded = false;
	this->effective_cost_available = false;
	this->critical_above_factor = 0.1;
	this->critical_below_factor = 0.1;
	sheddingLogFile = 0;
	delayEstimationFile = fopen("/home/thao/workspace/stream.test.thao/load_managing/Feb8/delay_estimation","wt");
	
	avg_capacity_usage = 0;
	cycle_count = 0;
	//headroom_temp = 0;
	
#ifdef _CTRL_LOAD_MANAGE_

	ctrl_avg_cost = 0.0;
	ctrl_in_tuple_count = 0; //the number of tuples actually get into the system (after shedding)
	ctrl_out_tuple_count = 0;
	ctrl_total_tuple_count = 0; //the total number of input tuples (before shedding)

	
	ctrl_queue_len = 0;
	
	ctrl_avg_delay = 0.0;	
	ctrl_pre_error = 0.0; //error(k-1)
	ctrl_pre_u = 0.0;
	
	ctrl_last_ts = 0;
	ctrl_current_shed_factor = 0;
	ctrl_sum_real_delay = 0;
	ctrl_count_real_delay = 0;
	ctrl_headroom = headroom_factor;
	ctrl_sum_total_input_tuples = 0;


#endif //_CTRL_LOAD_MANAGE_
}

LoadManager::~LoadManager() {
	if(sheddingLogFile)
		fclose(sheddingLogFile);
#ifdef _CTRL_LOAD_MANAGE_	
	if(delayEstimationFile)
		fclose(delayEstimationFile);
#endif
}

int LoadManager::addDropOperator(Physical::Operator *&op)
{
	ASSERT(op);
	if (numDrops == MAX_OPS_PER_TYPE)
		return -1;	
	drops[numDrops ++] = op;

	return 0;
} 
int LoadManager::addOutputOperator(Physical::Operator *&op)
{
	ASSERT(op);
	if (numOutputs == MAX_OPS_PER_TYPE){
		return -1;
	}
	outputs[numOutputs ++] = op;
	
	//pass the delay_tolerance constant to the output
	((Output*)op->instOp)->delay_tolerance = this->delay_tolerance;
	
	return 0;
	
} 
int LoadManager::addSourceOperator(Physical::Operator *&op)
{
	ASSERT(op);

	if (numInputs == MAX_OPS_PER_TYPE)
		return -1;	
	inputs[numInputs ++] = op;
	
	((StreamSource*)op->instOp)->input_rate_time_unit = this->input_rate_time_unit;
	return 0;
} 

int LoadManager::addOperator(Physical::Operator *&op)
{	
	ASSERT(op);

	if (numInputs == MAX_OPS_PER_TYPE)
		return -1;	
	ops[numOps ++] = op;
	
	return 0;
}
/*int LoadManager::setQueryPlan(Physical::Operator *&usedOps)
{
	ASSERT(usedOps);
	this->usedOps = usedOps;
	return 0;
}*/

int LoadManager::run(bool recomputeLoadCoefficient, int schedulingtype)
{
	double totalLoad = 0;
	//double cur_totalLoad = 0;
	double totalSourceLoad = 0;
	double totalEffectiveLoad = 0;
	bool still_abnormal = false;
	double load = 0, source_load =0, effective_load =0;
	double systemCapacityExpandingFactor = 2;
	
	
/*******************
 * COMPUTE CURRENT LOAD
 ********************/	
	if(recomputeLoadCoefficient) 
	{
		//recompute load coefficient based on the newly collected costs and selectivities
		/*Physical::Operator* op;
		op = usedOps;*/
		double coef = 0, snapshot_coef = 0, effective_coef =0;
		
		if(schedulingtype ==1 || schedulingtype ==10) //  RR scheduler or WRR scheduler
		{	
			/*HR and QC schedulers compute the statistics already, so 
			 * the load manager shouldn't recompute and mistakenly reset the cycle,
			 * it just uses the statistic calculated by the scheduler
			 * For RR, which does not touch the statistic collector, the load manager
			 * has to manage the statistic calculation.
			 */
			  
			/*while (op)
			{
				op->instOp->calculateLocalStats();
				op->instOp->resetLocalStatisticsComputationCycle();
				op = op->next;
			}*/
			for(int i=0;i<this->numOps; i++)
			{
				ops[i]->instOp->calculateLocalStats();
				ops[i]->instOp->resetLocalStatisticsComputationCycle();
			}
		}
		else
		{
			for(int i=0;i<this->numOps; i++)
			{
				if(ops[i]->kind == PO_STREAM_SOURCE||ops[i]->kind==PO_OUTPUT){
					ops[i]->instOp->calculateLocalStats();
					ops[i]->instOp->resetLocalStatisticsComputationCycle();
				}
			}
		}
				
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			if(snapshot_coef> 1.5*coef){
				abnormal_cost  = 2; //this information will be kept up to 2(?) cycles
				still_abnormal = true;
			}
			
			/*compute the new input rate during the last collecting cycle, 
			 * and reset for a new cycle
			 */
			 
			((StreamSource*)this->inputs[i]->instOp)->computeInputRate();
			((StreamSource*)this->inputs[i]->instOp)->resetInputRateComputationCycle();
			
			((StreamSource*)this->inputs[i]->instOp)->getLoad(load, effective_load, source_load);
			totalLoad += load;
			//printf("detailed load: %f\n", load);
			//cur_totalLoad += ((StreamSource*)this->inputs[i]->instOp)->getCurLoad();
			totalSourceLoad += source_load;
			if(effective_cost_available)
				totalEffectiveLoad += effective_load;
		}
	}
	else{
		//recompute the input rate and corresponsing load only
		for (unsigned int i =0; i<this->numInputs; i++)
		{
			/*compute the new input rate during the last collecting cycle, 
			 * and reset for a new cycle
			 */
			 
			((StreamSource*)this->inputs[i]->instOp)->computeInputRate();
			((StreamSource*)this->inputs[i]->instOp)->resetInputRateComputationCycle();
		
			((StreamSource*)this->inputs[i]->instOp)->getLoad(load, effective_load, source_load);
			totalLoad += load;
			
			//cur_totalLoad += ((StreamSource*)this->inputs[i]->instOp)->getCurLoad();
			totalSourceLoad += source_load;
			if(effective_cost_available)
				totalEffectiveLoad += effective_load; 
		}
	} 
	
	
	/*if(effective_cost_available)
	{	
		totalLoad = totalEffectiveLoad;
	}*/
	//printf("load: %f\n", totalLoad);
	updateAvgCapacityUsage(totalLoad);
/***********************
 * RESPONSE TIME MONITOR
***********************/	
	
	 //overload in the eye of response time monitor - abnormal response time
	bool abnormal_response_time = false; //delay target violated - OT
	bool critically_abnormal_response_time = false;
	bool accumulated_delay = false; // UT
	bool significantly_below_target = false;
	//bool critically_abnormal_response_time = false; //really over
	for(unsigned int o = 0; o< numOutputs ;o++)
	{
		((Output*)outputs[o]->instOp)->computeAvgResponseTime();
		
		if(((Output*)outputs[o]->instOp)->isAbnormalResponseTimeObserved())
		{
			abnormal_response_time= true;
			
			if(((Output*)outputs[o]->instOp)->isCriticallyAbnormalResponseTimeObserved(critical_above_factor))
			{
				critically_abnormal_response_time = true;
			}
			//break;
		}
		else if(((Output*)outputs[o]->instOp)->isSignificantlyBelowTargetObserved(critical_below_factor))
		{
			significantly_below_target = true;
		}
		if(((Output*)outputs[o]->instOp)->isAccummulatedDelayObserved(systemCapacityExpandingFactor))
		{
			accumulated_delay = true;  
		}
	}
	if(abnormal_response_time) significantly_below_target = false;
	/*if(critically_abnormal_response_time)
	{
		printf("%f %d %d \n", critical_below_factor, next_gap, initial_gap);
		printf("%lld:%d:%2.2f\n", 1000*((StreamSource*)inputs[numInputs-1]->instOp)->getLastInputTs(),((StreamSource*)inputs[0]->instOp)->drop_percent, headroom_factor);
		exit(1);
	}*/
	
	/*for each input_rate_time_unit, the system capacity available is that amount of time
	 * multiplied by some headroom factor (<1)
	 */
	
	double systemCapacity = headroom_factor* input_rate_time_unit;

/********************************
 * DECIDE FOR DIFFERENCE CASES
 * *****************************/
	//bool delay_observed = (abnormal_response_time && (abnormal_cost<=0));					
		
	double excessload = 0;
	double k=0;
	//printf("initial gap: %d, nextgap: %d\n", initial_gap, next_gap); 
	if(systemCapacity < totalLoad)
	{
		
		/****
		 * if the target is really violated
		 ****/ 
		if(abnormal_response_time){
			
			int additional_drop;
			excessload = (totalLoad - systemCapacity)/totalLoad;
		
			//additional_drop = ceil((1-(((1-excessload)*totalLoad - totalSourceLoad)/(totalLoad - totalSourceLoad)))*100);
			//additional_drop = ceil((1-(((1-excessload)*totalLoad)/totalLoad))*100);
			additional_drop = excessload*100;
			additional_drop = (additional_drop >=1)? additional_drop : 1;
			addDrop(additional_drop);
			overloadded = true;
			
			if(additional_drop <= 5) //this is for keeping track of the effective cost
				this->numOfStableSheddingCycles++;
			else
				this->numOfStableSheddingCycles = 0;
				
			if(critical_above_factor> ((double)initial_gap/100.0) + 0.001) critical_above_factor -= ((double)next_gap/100.0);
			if(critical_below_factor> ((double)initial_gap/100.0)+ 0.001) critical_below_factor -= ((double)next_gap/100.0);
			
		}
		else if(accumulated_delay)
		{
			/*accumulated delay observed, but the actual response time is less than the target
			 * we can allow more data if we are dropping something
			 * also, if we are dropping sth, it means the estimated capacity might be smaller than the actual one
			 * so, consider increasing it.
			 */
			
			
			if(overloadded){
				if(significantly_below_target)
				{	
					
					
					double max = totalLoad/(double)input_rate_time_unit;	
				
				 	k = ((max-headroom_factor)/headroom_factor)*100;
				 	if(k<1) k=1;
				
					headroom_factor += (log2(k+1)/(k))*(max - headroom_factor);
				
					/*else
					{
						headroom_factor = headroom_temp;
						headroom_temp = 0;
					}*/	
					/*if(removeDrop(1)==0)//no more overloadded
						 overloadded = false;*/
					
					critical_below_factor += ((double)next_gap/100.0);
					
					if(removeDrop(1)==0)//no more overloadded
						 overloadded = false;	
								
				}
				
			}
			if(!significantly_below_target)
				if(critical_below_factor>((double)initial_gap/100.0)+0.001) critical_below_factor -= ((double)next_gap/100.0);
			if(critical_above_factor> ((double)initial_gap/100.0)+0.001) critical_above_factor -= ((double)next_gap/100.0);
		}
		else {/*response time monitor says that its normal state: 
				*the capacity should be higher
				*/
			if(headroom_temp <=0.0001){
				double max = totalLoad/(double)input_rate_time_unit;	
				
				 k = ((max-headroom_factor)/headroom_factor)*100;
				 if(k<1) k=1;
				
				headroom_factor += (log2(k+1)/(k))*(max - headroom_factor);	
			}
			else
					{
						headroom_factor = headroom_temp;
						headroom_temp = 0;
					}
			
			
			//headroom_factor += (max - headroom_factor)/2;
			
			//printf("%f: %f\n",(log2(k+1)/k), headroom_factor);
			
			if(critical_above_factor> ((double)initial_gap/100.0)+0.001) critical_above_factor -= ((double)next_gap/100.0);
			if(critical_below_factor>((double)initial_gap/100.0)+0.001) critical_below_factor -= ((double)next_gap/100.0);
			
		}	
	}
	else{ // total load <= system capacity
		
		if(abnormal_response_time) { //delay target violated
			//there is disagreement between the two component: consider decreasing the estimated capacity
			if(abnormal_cost <=0 && critically_abnormal_response_time)
			{
				/*printf("%lld:%d:%2.2f\n", 1000*((StreamSource*)inputs[numInputs-1]->instOp)->getLastInputTs(),((StreamSource*)inputs[0]->instOp)->drop_percent, headroom_factor);
				exit(1);*/
				double min = totalLoad/(double)input_rate_time_unit;
				/*this can be just a temporary increase, so decrease the headroom_factor by haft of the distance,
		 		*/
				k = ((headroom_factor-min)/headroom_factor)*100;
				if(k<1) k=1;
					
				headroom_factor -= (log2(k+1)/(k))*(headroom_factor - min);
				//headroom_factor -= (headroom_factor - min)/2;
				//printf("%f: %f\n",(log2(k+1)/k), headroom_factor);
				//decrease the load a little bit
			
				addDrop(1);
				overloadded = true;
				critical_above_factor += ((double)next_gap/100.0);
			}
			if(!critically_abnormal_response_time) 
				if(critical_above_factor> ((double)initial_gap/100.0)+0.001) critical_above_factor -= ((double)next_gap/100.0);
			if(critical_below_factor> ((double)initial_gap/100.0)+0.001) critical_below_factor -= ((double)next_gap/100.0);			
		}
		else { //UT or normal
			
			if(overloadded){
				
				double freeload = 0;
				if(totalLoad >0){
					freeload = (systemCapacity - totalLoad)/totalLoad;
					//int removed_drop = floor(((((1+freeload)*totalLoad - totalSourceLoad)/(totalLoad - totalSourceLoad))-1)*100);
					//int removed_drop = round(((((1+freeload)*totalLoad)/totalLoad)-1)*100);
					int removed_drop = freeload*100;
					if (removed_drop<1) removed_drop = 1;
					if(removed_drop >0)
						if(removeDrop(removed_drop)==0)//no more overloadded
							 overloadded = false;
				
					if(removed_drop <= 5) //if the fluctation is small
						this->numOfStableSheddingCycles++;
					else
						this->numOfStableSheddingCycles = 0;
				}
			}
			if(critical_above_factor> ((double)initial_gap/100.0)+0.001) critical_above_factor -= ((double)next_gap/100.0);
			if(critical_below_factor> ((double)initial_gap/100.0)+0.001) critical_below_factor -= ((double)next_gap/100.0);
			
		}	
		
	}		
	
	/*if(overloadded && numOfStableSheddingCycles >=3 && !abnormal_cost){
	
		setHeavilyLoaddedCosts();	
		effective_cost_available = true;
	}	*/
			
	if(recomputeLoadCoefficient && !still_abnormal)
			abnormal_cost  = (abnormal_cost<=0)? abnormal_cost:abnormal_cost-1;		
					
	//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f:%d:%d:%d:%d:%f:%f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, headroom_factor, abnormal_response_time, critically_abnormal_response_time, accumulated_delay, significantly_below_target, critical_above_factor, critical_below_factor);
	}		
	/*if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((Drop *)drops[0]->instOp)->dropPercent, headroom_factor);
	}*/
	return 0;		
	 	
	
}

int LoadManager::findRelatedInputs_Drop(Physical::Operator *drop)
{
	for(unsigned int i=0;i<drop->numInputs;i++) //actually drop now has only one input
		findRelatedInput_Drop(drop->inputs[i],drop->instOp);
	return 0;
}
int LoadManager::findRelatedInput_Drop(Physical::Operator* op, Execution::Operator *drop)
{
	if(op->kind==PO_STREAM_SOURCE)
		((Drop*)drop)->addRelatedInput(op); //the method addRelatedInput includes eliminating duplicates
	else
		for(unsigned int i=0;i<op->numInputs;i++)
			findRelatedInput_Drop(op->inputs[i],drop);
	return 0;
		
}

int LoadManager::findRelatedOutputs_Drop(Physical::Operator* drop)
{
	for(int i=0;i< drop->numOutputs; i++)
		findRelatedOutput_Drop(drop->outputs[i],(Drop*)drop->instOp);
	return 0;
}
int LoadManager::findRelatedOutput_Drop(Physical::Operator* op, Drop *drop)
{
	if(op->kind==PO_OUTPUT)
		drop ->addRelatedOutput(op); //this checks for duplicate
	else
		for(unsigned int i=0; i<op->numOutputs;i++)
			findRelatedOutput_Drop(op->outputs[i],drop);
	return 0;
} 

int LoadManager::computeLoadCoefficient (Physical::Operator *op, double preSel, double& coef, double& cur_coef,double &effective_coef)
{
	
	coef = preSel*op->instOp->local_cost_per_tuple;
	cur_coef = preSel*op->instOp->snapshot_local_cost_per_tuple;
	if(effective_cost_available){
		//if(op->kind != PO_STREAM_SOURCE)
			effective_coef = preSel*op->instOp->effective_cost;
		//else
			//effective_coef = preSel*op->instOp->snapshot_local_cost_per_tuple;
	
	}
	
	if(op->kind != PO_OUTPUT){		
		double c, cur_c, effective_c;	
		for(unsigned int o =0; o< op->numOutputs; o++){
			computeLoadCoefficient(op->outputs[o], preSel*op->instOp->local_selectivity, c, cur_c,effective_c);
			coef +=c;
			cur_coef +=cur_c;
			if(effective_cost_available)			
				effective_coef +=effective_c;
			
		}
	}
	
#ifdef _CTRL_LOAD_MANAGE_
		op->instOp->ctrl_load_coef = coef/preSel;
#endif //_CTRL_LOAD_MANAGE		
	
	return 0;
		
}
int LoadManager::addDrop(int decrease_percent)
{
	//now assume that every drops is added the same drop_percent
	if(decrease_percent>100) decrease_percent = 100;
	
	for(unsigned int i = 0;i<numInputs; i++)
	{
		
		StreamSource * source = (StreamSource *)inputs[i]->instOp;
		int old = source->drop_percent;
		source->drop_percent = round(100-((100-source->drop_percent)*(100-decrease_percent)/100.0));
		
		if (source->drop_percent<=old && old <99) source->drop_percent = old+1; 
		//printf("drop add: %d; drop: %d\n", decrease_percent, source->drop_percent);
		if(source->drop_percent >=99 ) source->drop_percent = 99;
	}
	
	/*for(unsigned int i = 0;i<numDrops; i++)
	{
		Drop * drop = (Drop*)drops[i]->instOp;
		drop->dropPercent = 100-floor((100-drop->dropPercent)*(100-decrease_percent))/100;
		//printf("\ndrop add: %d; drop: %d", decrease_percent, drop->dropPercent);
	}*/ 
	return 0;
}
int LoadManager::removeDrop(int increase_percent)
{
	
	bool overload = false;
	//now assume that every drops is removed the same drop_percent
	for(unsigned int i=0;i<numInputs; i++)
	{
		StreamSource* source = (StreamSource*) inputs[i]->instOp;
		int old = source->drop_percent;
		int new_drop_percent = round(100-(double)((100+increase_percent)*(100-source->drop_percent))/(double)100); 
		if(new_drop_percent < 0)
			source->drop_percent = 0;
		else{
			
			if(new_drop_percent >= old && old>1)
				source->drop_percent = new_drop_percent-1;
			else
				source->drop_percent= new_drop_percent;	
			overload = true;
		}
		//printf("drop remove: %d; drop: %d\n", increase_percent, source->drop_percent);	
	}
	
	if(!overload) return 0; //no more shedding applied
	else return -1;  
}

int LoadManager::setHeavilyLoaddedCosts()
{
	/*Physical::Operator *op = usedOps;
	while(op){
	
		op->instOp->setHeavilyLoaddedCost();
		op = op->next;
	}*/
	
	for(int i=0;i<numOps;i++)
		ops[i]->instOp->setHeavilyLoaddedCost();
	return 0;
}

/*
 * PURDUE's CTRL-BASED LOAD SHEDDING
 */
 #ifdef _CTRL_LOAD_MANAGE_


int LoadManager::runCtrlLoadMgr(){
	 //run the Purdue control-based version 
	
	/*now we used the run-time calculated average cost for ctrl_avg_cost,
	 * experiments with fixed cost should also be considered.
	 */
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();
	
	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;		 	
	
	ctrl_total_tuple_count = 0;
	ctrl_out_tuple_count = 0;

	
	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	//while (op)
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		//update the ctrl_out_tuple_count
		if(op->kind!=PO_STREAM_SOURCE){
			ctrl_out_tuple_count += op->instOp->ctrl_out_tuple_count;
			//printf("op kind: %d, op count: %lld\n",op->kind,op->instOp->ctrl_out_tuple_count);
		}
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			if(effective_cost_available)
				coef = effective_coef;
			ctrl_sum_cost +=coef; //should consider experiments with other coef as well
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts);
			
			ctrl_total_tuple_count += total_input_tuples;

			double compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			
			ctrl_compensation += compensation;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
						
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + compensation;
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
			
	} 
	
	//if all source queue info has been adjusted
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	//printf("%f\n", ctrl_compensation);
	
	ctrl_in_tuple_count = (100-ctrl_current_shed_factor)*ctrl_total_tuple_count/100 + ctrl_compensation;
	
	
	//the average cost to processed a tuple is the average of the estimated processing cost of all input path
	//this is just intuitively correct for no-fan-out plans.
	
	ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//printf("%f\n", ctrl_avg_cost);
	
	
	ctrl_queue_len += (ctrl_in_tuple_count - ctrl_out_tuple_count);
	
	//printf("queue: %f, in: %f, out: %f \n",ctrl_queue_len, ctrl_in_tuple_count, ctrl_out_tuple_count);
	
	//estimating y_k, following what is implemented in the code, not what is described in the paper!
	double ctrl_y_k;
	double ctrl_error;
	double ctrl_u;
	
	//printf("%lld ::: %f\n", ctrl_queue_len + (long long int)ctrl_in_tuple_count, (double)ctrl_period *(ctrl_headroom/ctrl_avg_cost) );
	//in the paper: ctrl_y_k = ctrl_queue_len*(ctrl_avg_cost/headroom_factor)
	if(ctrl_queue_len + ctrl_in_tuple_count < (double)ctrl_period *(ctrl_headroom/ctrl_avg_cost) )
	{   // no waiting in the queue, delay = processing time only
		ctrl_y_k = ctrl_avg_cost/ctrl_headroom ;
		
	}
	else
	{
		//hmmm, is this correct?
		ctrl_y_k = (ctrl_queue_len /*+ ctrl_in_tuple_count/2*/) * (ctrl_avg_cost /ctrl_headroom) //waiting time 
					+ ctrl_avg_cost /ctrl_headroom ;
		
		
		
	}
		
	//the base-line approach:
	
	//ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* (ctrl_headroom/ctrl_avg_cost) - ctrl_queue_len;
	
	
	
	
	
	//the control-based approach
	  
	ctrl_error = CONTROL_DELAY_TARGET - ctrl_y_k;
	

	ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * ((double)ctrl_headroom/ctrl_avg_cost)
			  - ctrl_a*ctrl_pre_u;
	//ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * (ctrl_headroom/(ctrl_avg_cost*ctrl_period))
	//		  - ctrl_a*ctrl_pre_u;
	
	
	ctrl_pre_u = ctrl_u;
	ctrl_pre_error = ctrl_error;

	//the total number of tuple can enter the virtual queue: u_k + expected maximum f_out
	// I think it should be like this
	ctrl_u += (double)ctrl_period*(ctrl_headroom/ctrl_avg_cost);
	//but this is what is in Yicheng's code:
	//ctrl_u += (double)ctrl_period/ctrl_avg_cost;
	
	//printf("y: %f, u: %f \n", ctrl_y_k, ctrl_u-ctrl_period/ctrl_avg_cost);
	//calculate the shedding amount
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_total_tuple_count)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
		
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
	
	
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, headroom_factor);
	}	
	
	
	if(delayEstimationFile){
		//fprintf(delayEstimationFile, "%lld    %.0f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),ctrl_y_k);
		fprintf(delayEstimationFile, "%lld    %.0f\n", ctrl_last_ts - ((StreamSource*)inputs[0]->instOp)->system_start_time + ctrl_period/2 ,ctrl_y_k);
	}
	
	return 0;
}

int LoadManager::runBaselineLoadMgr1(){ //with the long term avg cost
	 //run the Baseline version 
	
	/*now we used the run-time calculated average cost for ctrl_avg_cost,
	 * experiments with fixed cost should also be considered.
	 */
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();
	
	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;		 	
	
	ctrl_total_tuple_count = 0;
	ctrl_out_tuple_count = 0;

	
	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	//while (op)
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		//update the ctrl_out_tuple_count
		if(op->kind!=PO_STREAM_SOURCE){
			ctrl_out_tuple_count += op->instOp->ctrl_out_tuple_count;
			//printf("op kind: %d, op count: %lld\n",op->kind,op->instOp->ctrl_out_tuple_count);
		}
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			if(effective_cost_available)
				coef = effective_coef;
			ctrl_sum_cost +=coef; //should consider experiments with other coef as well
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts);
			
			ctrl_total_tuple_count += total_input_tuples;

			double compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			
			ctrl_compensation += compensation;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
						
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + compensation;
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
			
	} 
	
	//if all source queue info has been adjusted
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	//printf("%f\n", ctrl_compensation);
	
	ctrl_in_tuple_count = (100-ctrl_current_shed_factor)*ctrl_total_tuple_count/100 + ctrl_compensation;
	
	
	//the average cost to processed a tuple is the average of the estimated processing cost of all input path
	//this is just intuitively correct for no-fan-out plans.
	
	//ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//printf("%f\n", ctrl_avg_cost);
	
	ctrl_sum_total_input_tuples +=ctrl_in_tuple_count;
	
	ctrl_avg_cost = ((double)(ctrl_now - ((StreamSource*)inputs[0]->instOp)->system_start_time))/(double)ctrl_sum_total_input_tuples;
	
	double ctrl_avg_load = (double)ctrl_sum_total_input_tuples / (((double)(ctrl_now - ((StreamSource*)inputs[0]->instOp)->system_start_time))/ctrl_period);
	
	ctrl_queue_len += (ctrl_in_tuple_count - ctrl_out_tuple_count);
	
	double ctrl_u;
	
		
	//the base-line approach:
	
	//ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* (ctrl_headroom/ctrl_avg_cost) - ctrl_queue_len;
	ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)/ctrl_avg_cost - ctrl_queue_len;
	
	
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_avg_load)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
		
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
	
	
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, headroom_factor);
	}	
	
	return 0;
}


int LoadManager::runBaselineLoadMgr2(){ //with the short term avg cost
	 //run the Baseline version 
	
	/*now we used the run-time calculated average cost for ctrl_avg_cost,
	 * experiments with fixed cost should also be considered.
	 */
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();
	
	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;		 	
	
	ctrl_total_tuple_count = 0;
	ctrl_out_tuple_count = 0;

	
	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		//update the ctrl_out_tuple_count
		if(op->kind!=PO_STREAM_SOURCE){
			ctrl_out_tuple_count += op->instOp->ctrl_out_tuple_count;
			//printf("op kind: %d, op count: %lld\n",op->kind,op->instOp->ctrl_out_tuple_count);
		}
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			if(effective_cost_available)
				coef = effective_coef;
			ctrl_sum_cost +=coef; //should consider experiments with other coef as well
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts);
			
			ctrl_total_tuple_count += total_input_tuples;

			double compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			
			ctrl_compensation += compensation;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
						
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + compensation;
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
			
	} 
	
	//if all source queue info has been adjusted
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	//printf("%f\n", ctrl_compensation);
	
	ctrl_in_tuple_count = (100-ctrl_current_shed_factor)*ctrl_total_tuple_count/100 + ctrl_compensation;
	
	
	//the average cost to processed a tuple is the average of the estimated processing cost of all input path
	//this is just intuitively correct for no-fan-out plans.
	
	ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//printf("%f\n", ctrl_avg_cost);
	
	ctrl_queue_len += (ctrl_in_tuple_count - ctrl_out_tuple_count);
	
	double ctrl_u;
	
		
	//the base-line approach:
	
	ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* (ctrl_headroom/ctrl_avg_cost) - ctrl_queue_len;
	//ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)/ctrl_avg_cost - ctrl_queue_len;
	
	
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_total_tuple_count)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
		
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
	
	
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, headroom_factor);
	}	
	
	
	return 0;
}
int LoadManager::runExtendedBaselineCtrlLoadMgr(){

 //run the Purdue control-based version 
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();

	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;
////////////////////////////
///COMPUTE THE CURRENT LOAD (aka, previously ctrl_in_tuple_count)
/////////////////////////////

	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	
	//while (op)
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	double ctrl_total_comingLoad = 0; //the load comming to the system in the past period, before shedding
	double ctrl_queuingLoad = 0;
	double ctrl_comingLoad = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			ctrl_sum_cost +=coef;
			
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts); 
			ctrl_total_comingLoad  += 	total_input_tuples* coef;
										
			ctrl_compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
			
			//update the number of queuing tuples of the sources
			
			((StreamSource*)this->inputs[i]->instOp)->ctrl_num_of_queuing_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + ctrl_compensation;
			//printf("%f\n", ((StreamSource*)this->inputs[i]->instOp)->ctrl_num_of_queuing_tuples);
			//if(total_input_tuples <0) exit(1);
			ctrl_comingLoad += ((100.0-ctrl_current_shed_factor)*total_input_tuples/100 + ctrl_compensation)*coef;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + ctrl_compensation;
			
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
			
	} 
	//if all source queue info has been adjusted
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	//the total quueing load in the system:
	ctrl_queuingLoad  = computeQueuingLoad();
	
	//avg cost
	ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//estimating y_k, following what is implemented in the code, not what is described in the paper!
	double ctrl_y_k;
	double ctrl_u;
	
	//the base-line approach:
	
	ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* ctrl_headroom - ctrl_queuingLoad;
	
	
	//calculate the shedding amount
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_total_comingLoad)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
	
	
	//ctrl_last_ts = mytime.getTime();
	
	
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
		
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, ctrl_headroom);
	}	
	
	
	if(delayEstimationFile){
		//fprintf(delayEstimationFile, "%lld    %.0f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),ctrl_y_k);
		fprintf(delayEstimationFile, "%lld    %.0f\n", ctrl_last_ts - ((StreamSource*)inputs[0]->instOp)->system_start_time + ctrl_period/2 ,ctrl_y_k);
	}
	
	return 0;

}

int LoadManager::runExtendedCtrlLoadMgr(){
	 //run the Purdue control-based version 
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();

	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;
////////////////////////////
///COMPUTE THE CURRENT LOAD (aka, previously ctrl_in_tuple_count)
/////////////////////////////

	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	
	//while (op)
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	double ctrl_total_comingLoad = 0; //the load comming to the system in the past period, before shedding
	double ctrl_queuingLoad = 0;
	double ctrl_comingLoad = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			ctrl_sum_cost +=coef;
			
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts); 
			ctrl_total_comingLoad  += 	total_input_tuples* coef;
										
			ctrl_compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
			
			//update the number of queuing tuples of the sources
			
			((StreamSource*)this->inputs[i]->instOp)->ctrl_num_of_queuing_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + ctrl_compensation;
			//printf("%f\n", ((StreamSource*)this->inputs[i]->instOp)->ctrl_num_of_queuing_tuples);
			//if(total_input_tuples <0) exit(1);
			ctrl_comingLoad += ((100.0-ctrl_current_shed_factor)*total_input_tuples/100 + ctrl_compensation)*coef;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + ctrl_compensation;
			
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
			
	} 
	//if all source queue info has been adjusted
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	//the total quueing load in the system:
	ctrl_queuingLoad  = computeQueuingLoad();
	
	//avg cost
	ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//estimating y_k, following what is implemented in the code, not what is described in the paper!
	double ctrl_y_k;
	double ctrl_error;
	double ctrl_u;
	
	//printf("%lld ::: %f\n", ctrl_queue_len + (long long int)ctrl_in_tuple_count, (double)ctrl_period *(ctrl_headroom/ctrl_avg_cost) );
	//in the paper: ctrl_y_k = ctrl_queue_len*(ctrl_avg_cost/headroom_factor)
	if(ctrl_queuingLoad + ctrl_comingLoad < (double)ctrl_period * ctrl_headroom )
	{   // no waiting in the queue, delay = processing time only
		ctrl_y_k = ctrl_avg_cost/ctrl_headroom ;
		
	}
	else
	{
		//hmmm, is this correct?
		ctrl_y_k = ctrl_queuingLoad/ctrl_headroom //waiting time 
					+ ctrl_avg_cost /ctrl_headroom ;
		
	}
		
	//the base-line approach:
	
	//ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* (ctrl_headroom/ctrl_avg_cost) - ctrl_queue_len;
	
	
	
	
	
	//the control-based approach
	  
	ctrl_error = CONTROL_DELAY_TARGET - ctrl_y_k;
	

	ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * ((double)ctrl_headroom)
			  - ctrl_a*ctrl_pre_u;
	//ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * (ctrl_headroom/(ctrl_avg_cost*ctrl_period))
	//		  - ctrl_a*ctrl_pre_u;
	
	
	ctrl_pre_u = ctrl_u;
	ctrl_pre_error = ctrl_error;

	//the total number of tuple can enter the virtual queue: u_k + expected maximum f_out
	// I think it should be like this
	ctrl_u += (double)ctrl_period*ctrl_headroom;
	//but this is what is in Yicheng's code:
	//ctrl_u += (double)ctrl_period/ctrl_avg_cost;
	
	//printf("y: %f, queuing load: %f, coming load: %f, headroom: %f \n", ctrl_y_k, ctrl_queuingLoad, ctrl_comingLoad, ctrl_headroom);
	//calculate the shedding amount
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_total_comingLoad)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
	
	
	//ctrl_last_ts = mytime.getTime();
	
	
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
	
	
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, ctrl_headroom);
	}	
	
	
	if(delayEstimationFile){
		//fprintf(delayEstimationFile, "%lld    %.0f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),ctrl_y_k);
		fprintf(delayEstimationFile, "%lld    %.0f\n", ctrl_last_ts - ((StreamSource*)inputs[0]->instOp)->system_start_time + ctrl_period/2 ,ctrl_y_k);
	}
	
	return 0;
}


int LoadManager::runExtendedDynamicCtrlLoadMgr(){
	 //run the Purdue control-based version 
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();

	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;
/////////////////////////
//RESPONSE TIME MONITOR: to adjust the headroom factor
///////////////////////
	//printf("initial gap: %d\n", initial_gap);
	if(abs(ctrl_pre_error) < ((double)initial_gap/100.0)*CONTROL_DELAY_TARGET && ctrl_pre_error >0 && ctrl_count_real_delay>=0) //shedding is applied, which is when the response time should be around the target
	{	
		//now assume all output has the same response time target and RR is used for scheduling
		//so we only need to monitor one of the output
		
		((Output*)outputs[0]->instOp)->computeAvgResponseTime();
		//if(ctrl_count_real_delay > 0 && 
		//	abs(((Output*)outputs[0]->instOp)->avg_response_time - ctrl_sum_real_delay/ctrl_count_real_delay) < 0.5*(ctrl_sum_real_delay/ctrl_count_real_delay)) 
			ctrl_sum_real_delay += ((Output*)outputs[0]->instOp)->avg_response_time;
			ctrl_count_real_delay ++;
							
		
		if(ctrl_count_real_delay >=50)
		{
			double ctrl_avg_real_delay = ctrl_sum_real_delay/ctrl_count_real_delay;
			ctrl_headroom = ctrl_headroom*((double)CONTROL_DELAY_TARGET/ctrl_avg_real_delay);
			ctrl_sum_real_delay = 0;
			ctrl_count_real_delay = -10; //stop monitoring the for a while so that the real delay reflect the new value of H 
			//printf("%f, real: %f \n", ctrl_headroom,ctrl_avg_real_delay);
		}
			
	}
	else
	{
		if(ctrl_count_real_delay<0) ctrl_count_real_delay ++;
	}
	
	
	
////END OF HEADROOM ADJUSTMENT	
	
////////////////////////////
///COMPUTE THE CURRENT LOAD (aka, previously ctrl_in_tuple_count)
/////////////////////////////

	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	
	//while (op)
	for(int i=0;i<numOps; i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	double ctrl_total_comingLoad = 0; //the load comming to the system in the past period, before shedding
	double ctrl_queuingLoad = 0;
	double ctrl_comingLoad = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			ctrl_sum_cost +=coef;
			
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts); 
			ctrl_total_comingLoad  += 	total_input_tuples* coef;
										
			ctrl_compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
			
			//update the number of queuing tuples of the sources
			
			((StreamSource*)this->inputs[i]->instOp)->ctrl_num_of_queuing_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + ctrl_compensation;
			//printf("%f\n", ((StreamSource*)this->inputs[i]->instOp)->ctrl_num_of_queuing_tuples);
			//if(total_input_tuples <0) exit(1);
			ctrl_comingLoad += ((100.0-ctrl_current_shed_factor)*total_input_tuples/100 + ctrl_compensation)*coef;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + ctrl_compensation;
			
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
			
	} 
	//if all source queue info has been adjusted
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	//the total quueing load in the system:
	ctrl_queuingLoad  = computeQueuingLoad();
	
	//avg cost
	ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//estimating y_k, following what is implemented in the code, not what is described in the paper!
	double ctrl_y_k;
	double ctrl_error;
	double ctrl_u;
	
	//printf("%lld ::: %f\n", ctrl_queue_len + (long long int)ctrl_in_tuple_count, (double)ctrl_period *(ctrl_headroom/ctrl_avg_cost) );
	//in the paper: ctrl_y_k = ctrl_queue_len*(ctrl_avg_cost/headroom_factor)
	if(ctrl_queuingLoad + ctrl_comingLoad < (double)ctrl_period * ctrl_headroom )
	{   // no waiting in the queue, delay = processing time only
		ctrl_y_k = ctrl_avg_cost/ctrl_headroom ;
		
	}
	else
	{
		//hmmm, is this correct?
		ctrl_y_k = ctrl_queuingLoad/ctrl_headroom //waiting time 
					+ ctrl_avg_cost /ctrl_headroom ;
		
	}
		
	//the base-line approach:
	
	//ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* (ctrl_headroom/ctrl_avg_cost) - ctrl_queue_len;
	
	
	
	
	
	//the control-based approach
	  
	ctrl_error = CONTROL_DELAY_TARGET - ctrl_y_k;
	

	ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * ((double)ctrl_headroom)
			  - ctrl_a*ctrl_pre_u;
	//ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * (ctrl_headroom/(ctrl_avg_cost*ctrl_period))
	//		  - ctrl_a*ctrl_pre_u;
	
	
	ctrl_pre_u = ctrl_u;
	ctrl_pre_error = ctrl_error;

	//the total number of tuple can enter the virtual queue: u_k + expected maximum f_out
	// I think it should be like this
	ctrl_u += (double)ctrl_period*ctrl_headroom;
	//but this is what is in Yicheng's code:
	//ctrl_u += (double)ctrl_period/ctrl_avg_cost;
	
	//printf("y: %f, queuing load: %f, coming load: %f, headroom: %f \n", ctrl_y_k, ctrl_queuingLoad, ctrl_comingLoad, ctrl_headroom);
	//calculate the shedding amount
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_total_comingLoad)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
	
	
	//ctrl_last_ts = mytime.getTime();
	
	
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
	
	
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, ctrl_headroom);
	}	
	
	
	if(delayEstimationFile){
		//fprintf(delayEstimationFile, "%lld    %.0f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),ctrl_y_k);
		fprintf(delayEstimationFile, "%lld    %.0f\n", ctrl_last_ts - ((StreamSource*)inputs[0]->instOp)->system_start_time + ctrl_period/2 ,ctrl_y_k);
	}
	
	return 0;
}


int LoadManager::runDynamicCtrlLoadMgr(){
	 //run the Purdue control-based version 
	
	Monitor::Timer mytime;
	unsigned long long int ctrl_now = mytime.getTime();
	
	ctrl_period = ctrl_now - ctrl_last_ts;		
	ctrl_last_ts = ctrl_now;
	
	double ctrl_in_tuple_count_p = 0;		 	
	
	ctrl_total_tuple_count = 0;
	ctrl_out_tuple_count = 0;

	
	//recompute load coefficient based on the newly collected costs and selectivities
	Physical::Operator* op;
	//op = usedOps;
	
	double coef = 0, snapshot_coef = 0, effective_coef =0;
	
	
/////////////////////////
//RESPONSE TIME MONITOR: to adjust the headroom factor
///////////////////////

	if(abs(ctrl_pre_error) < ((double)initial_gap/100.0)*CONTROL_DELAY_TARGET && ctrl_count_real_delay>=0) //shedding is applied, which is when the response time should be around the target
	{	
		//now assume all output has the same response time target and RR is used for scheduling
		//so we only need to monitor one of the output
		
		((Output*)outputs[0]->instOp)->computeAvgResponseTime();
		ctrl_sum_real_delay += ((Output*)outputs[0]->instOp)->avg_response_time;
		ctrl_count_real_delay ++;					
		
		if(ctrl_count_real_delay >=50)
		{
			double ctrl_avg_real_delay = ctrl_sum_real_delay/ctrl_count_real_delay;
			ctrl_headroom = ctrl_headroom*((double)CONTROL_DELAY_TARGET/ctrl_avg_real_delay);
			ctrl_sum_real_delay = 0;
			ctrl_count_real_delay = -10; //stop monitoring the for a while so that the real delay reflect the new value of H 
			//printf("%f, real: %f \n", ctrl_headroom,ctrl_avg_real_delay);
		}
			
	}
	else
	{
		if(ctrl_count_real_delay<0) ctrl_count_real_delay ++;
	}
	
	
	
////END OF HEADROOM ADJUSTMENT	
	
	
	//while (op)
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		op->instOp->calculateLocalStats(); //////actually we can update ctrl_out_tuple_count here
		
		//update the ctrl_out_tuple_count
		if(op->kind!=PO_STREAM_SOURCE){
			ctrl_out_tuple_count += op->instOp->ctrl_out_tuple_count;
			//printf("op kind: %d, op count: %lld\n",op->kind,op->instOp->ctrl_out_tuple_count);
		}
		else //stream source: discarded tuple is dropped ones
			ctrl_in_tuple_count_p -= op->instOp->ctrl_out_tuple_count;
		
		op->instOp->resetLocalStatisticsComputationCycle();
		//op = op->next;
	}
	
	//ctrl_period = ctrl_now - ctrl_last_ts;
	
		
	double ctrl_sum_cost = 0;
	double ctrl_compensation = 0;
	//ctrl_total_tuple_count scaled by input_rate_time_unit, which = total input rate
	bool adjusted = true;
	for (unsigned int i = 0; i<this->numInputs; i++)
	{
			computeLoadCoefficient(inputs[i],1, coef, snapshot_coef, effective_coef);
			
			((StreamSource*)this->inputs[i]->instOp)->setLoadCoefficient(coef, snapshot_coef, effective_coef);
			
			if(effective_cost_available)
				coef = effective_coef;
			ctrl_sum_cost +=coef; //should consider experiments with other coef as well
			
			double total_input_tuples = ((StreamSource*)this->inputs[i]->instOp)->get_incoming_tuples(ctrl_last_ts);
			ctrl_total_tuple_count += total_input_tuples;
			
			double compensation = ((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation;
			ctrl_compensation += compensation;
			
			((StreamSource*)this->inputs[i]->instOp)->ctrl_compensation = 0;
			//sctrl_in_tuple_count_p += ((StreamSource*)this->inputs[i]->instOp)->numOfIncomingTuples;
			//printf("%lld\n", ((StreamSource*)this->inputs[i]->instOp)->numOfIncomingTuples);
			//((StreamSource*)this->inputs[i]->instOp)->computeInputRate();
			//printf("read: %f\n", ((StreamSource*)this->inputs[i]->instOp)->inputRate);
			//((StreamSource*)this->inputs[i]->instOp)->resetInputRateComputationCycle();
			
			((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples += (100.0-ctrl_current_shed_factor)*total_input_tuples/100.0 + compensation;
			if(((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted ==false)
				adjusted = false;
	} 
	
	//if all source queue info has been adjusted, set new checkpoint
	if(adjusted ==true)
	{
		for (unsigned int i = 0; i<this->numInputs; i++)
		{
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_ts = ctrl_last_ts;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_checkpoint_estimated_total_incoming_tuples = ((StreamSource*)this->inputs[i]->instOp)->ctrl_estimated_total_incoming_tuples;
			((StreamSource*)this->inputs[i]->instOp)->ctrl_adjusted = false;		
		} 
	}
	
	ctrl_in_tuple_count = (100-ctrl_current_shed_factor)*ctrl_total_tuple_count/100 + ctrl_compensation;
	
	//the average cost to processed a tuple is the average of the estimated processing cost of all input path
	//this is just intuitively correct for no-fan-out plans.
	
	ctrl_avg_cost = ctrl_sum_cost/(double)this->numInputs;
	
	//printf("%f\n", ctrl_avg_cost);
	
	
	ctrl_queue_len += (ctrl_in_tuple_count - ctrl_out_tuple_count);
	
	//estimating y_k, following what is implemented in the code, not what is described in the paper!
	double ctrl_y_k;
	double ctrl_error;
	double ctrl_u;
	
	//printf("%lld ::: %f\n", ctrl_queue_len + (long long int)ctrl_in_tuple_count, (double)ctrl_period *(ctrl_headroom/ctrl_avg_cost) );
	//in the paper: ctrl_y_k = ctrl_queue_len*(ctrl_avg_cost/headroom_factor)
	if(ctrl_queue_len + ctrl_in_tuple_count < (double)ctrl_period *(ctrl_headroom/ctrl_avg_cost) )
	{   // no waiting in the queue, delay = processing time only
		ctrl_y_k = ctrl_avg_cost/ctrl_headroom ;
		
	}
	else
	{
		//hmmm, is this correct?
		ctrl_y_k = (ctrl_queue_len /*+ ctrl_in_tuple_count/2*/) * (ctrl_avg_cost /ctrl_headroom) //waiting time 
					+ ctrl_avg_cost /ctrl_headroom ;
		
		
		
	}
		
	//the base-line approach:
	
	//ctrl_u = (CONTROL_DELAY_TARGET + ctrl_period)* (ctrl_headroom/ctrl_avg_cost) - ctrl_queue_len;
	
	
	
	
	
	//the control-based approach
	  
	ctrl_error = CONTROL_DELAY_TARGET - ctrl_y_k;
	

	ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * ((double)ctrl_headroom/ctrl_avg_cost)
			  - ctrl_a*ctrl_pre_u;
	//ctrl_u = (ctrl_b_0*ctrl_error + ctrl_b_1*ctrl_pre_error) * (ctrl_headroom/(ctrl_avg_cost*ctrl_period))
	//		  - ctrl_a*ctrl_pre_u;
	
	
	ctrl_pre_u = ctrl_u;
	ctrl_pre_error = ctrl_error;

	//the total number of tuple can enter the virtual queue: u_k + expected maximum f_out
	// I think it should be like this
	ctrl_u += (double)ctrl_period*(ctrl_headroom/ctrl_avg_cost);
	//but this is what is in Yicheng's code:
	//ctrl_u += (double)ctrl_period/ctrl_avg_cost;
	
	//printf("y: %f, u: %f \n", ctrl_y_k, ctrl_u-ctrl_period/ctrl_avg_cost);
	//calculate the shedding amount
	int ctrl_dropPercent;
	//printf("error: %f, y: %f, u: %f, total in: %lld \n", ctrl_error, ctrl_y_k, ctrl_u, ctrl_total_tuple_count);
	
	ctrl_dropPercent = 100 - round((ctrl_u/(double)ctrl_total_tuple_count)*100);
	
		
	if(ctrl_dropPercent < 0 ) ctrl_dropPercent = 0;
	if(ctrl_dropPercent >100) ctrl_dropPercent = 100;
	
	
	
	//ctrl_last_ts = mytime.getTime();
	
	
	this->setDropPercent(ctrl_dropPercent, ctrl_last_ts);
	
	this->ctrl_current_shed_factor = ctrl_dropPercent;
	
	
	
		//for experiments only: log to see how much drop is used
	if(sheddingLogFile){
		int rate = round (((StreamSource*)inputs[0]->instOp)->inputRate);
		fprintf(sheddingLogFile, "%lld:%d:%d:%2.2f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),rate,((StreamSource*)inputs[0]->instOp)->drop_percent, ctrl_headroom);
	}	
	
	
	if(delayEstimationFile){
		//fprintf(delayEstimationFile, "%lld    %.0f\n", 1000*((StreamSource*)inputs[0]->instOp)->getLastInputTs(),ctrl_y_k);
		fprintf(delayEstimationFile, "%lld    %.0f\n", ctrl_last_ts - ((StreamSource*)inputs[0]->instOp)->system_start_time + ctrl_period/2 ,ctrl_y_k);
	}
	
	return 0;
}
double LoadManager::computeQueuingLoad()
{
	double qLoad;
	Physical::Operator* op;
	//op= usedOps;
	//while(op)
	for(int i=0;i<numOps;i++)
	{
		op = ops[i];
		//if(op->kind == PO_SELECT)
		//printf("type: %d, %f\n",op->kind, op->instOp-> ctrl_num_of_queuing_tuples);
		qLoad +=op->instOp-> ctrl_num_of_queuing_tuples*op->instOp->ctrl_load_coef;
		//op = op->next;
	}
	return qLoad;
}

int LoadManager::setDropPercent(int percent, unsigned long long int effective_time)
{
	for(unsigned int i = 0;i<numInputs; i++)
	{
		StreamSource * source = (StreamSource*)inputs[i]->instOp;
		
		source->push_drop_info((unsigned long long int)percent,effective_time);
		
		//source->drop_percent = (unsigned int)percent;
		//printf("effective time: %lld\n", effective_time);
	}
	
	//now assume that every drops is added the same drop_percent
	/*for(unsigned int i = 0;i<numDrops; i++)
	{
		Drop * drop = (Drop*)drops[i]->instOp;
		drop->dropPercent = percent;
		//printf("\ndrop add: %d", drop->dropPercent);
	}*/ 
	return 0;
}
#endif //_CTRL_LOAD_MANAGE_
 
void LoadManager::incoming_tuples_monitor()
{
	printf("\nreal: %f; estimated: %f\n", ((StreamSource*)inputs[0]->instOp)->ctrl_actual_total_incoming_tuples, ((StreamSource*)inputs[0]->instOp)->ctrl_estimated_total_incoming_tuples);
}
	

void LoadManager::resetCapacityUsageTracking()
{
	avg_capacity_usage = 0;
	cycle_count = 0;
}

void LoadManager::updateAvgCapacityUsage(double totalLoad)
{
	double current_load =  (totalLoad/(100-((StreamSource*)inputs[0]->instOp)->drop_percent))*100;
	double current_usage = (current_load/(headroom_factor* input_rate_time_unit))*100;
	
	avg_capacity_usage = (avg_capacity_usage*cycle_count + current_usage)/(++cycle_count);
	//printf("%d: %f: %f\n", cycle_count, totalLoad, current_usage );
}
